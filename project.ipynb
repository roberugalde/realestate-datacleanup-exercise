{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "innocent-university",
   "metadata": {},
   "source": [
    "# Real Estate Clean up\n",
    "\n",
    "This is a real dataset, and it was downloaded using web scraping techniques. The data contains registers from **Fotocasa** which is one of the most popular real estate websites in Spain. Please, do not do this (web scraping) unless it is for academic purposes.\n",
    "\n",
    "The dataset was downloaded a few years ago by Henry Navarro, and in no case were economic returns obtained from it.\n",
    "\n",
    "It contains thousands of data from real houses published on the web www.fotocasa.com. Your goal is to extract as much information as possible with the knowledge you have so far about data science, for example what is the most expensive house in the entire dataset?\n",
    "\n",
    "Let's start with precisely that question... Good luck!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "multiple-glass",
   "metadata": {},
   "source": [
    "#### Exercise 00. Read the dataset assets/real_estate.csv and try to visualize the table (★☆☆)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "frank-heath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id_realEstates</th>\n",
       "      <th>isNew</th>\n",
       "      <th>realEstate_name</th>\n",
       "      <th>phone_realEstate</th>\n",
       "      <th>url_inmueble</th>\n",
       "      <th>rooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>surface</th>\n",
       "      <th>price</th>\n",
       "      <th>...</th>\n",
       "      <th>level4Id</th>\n",
       "      <th>level5Id</th>\n",
       "      <th>level6Id</th>\n",
       "      <th>level7Id</th>\n",
       "      <th>level8Id</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>zipCode</th>\n",
       "      <th>customZone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>153771986</td>\n",
       "      <td>False</td>\n",
       "      <td>ferrari 57 inmobiliaria</td>\n",
       "      <td>912177526.0</td>\n",
       "      <td>https://www.fotocasa.es/es/comprar/vivienda/ma...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>195000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40,2948276786438</td>\n",
       "      <td>-3,44402412135624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>153867863</td>\n",
       "      <td>False</td>\n",
       "      <td>tecnocasa fuenlabrada ferrocarril</td>\n",
       "      <td>916358736.0</td>\n",
       "      <td>https://www.fotocasa.es/es/comprar/vivienda/ma...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40,28674</td>\n",
       "      <td>-3,79351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>153430440</td>\n",
       "      <td>False</td>\n",
       "      <td>look find boadilla</td>\n",
       "      <td>916350408.0</td>\n",
       "      <td>https://www.fotocasa.es/es/comprar/vivienda/ma...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>390000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40,4115646786438</td>\n",
       "      <td>-3,90662252135624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>152776331</td>\n",
       "      <td>False</td>\n",
       "      <td>tecnocasa fuenlabrada ferrocarril</td>\n",
       "      <td>916358736.0</td>\n",
       "      <td>https://www.fotocasa.es/es/comprar/vivienda/ma...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40,2853785786438</td>\n",
       "      <td>-3,79508142135624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>153180188</td>\n",
       "      <td>False</td>\n",
       "      <td>ferrari 57 inmobiliaria</td>\n",
       "      <td>912177526.0</td>\n",
       "      <td>https://www.fotocasa.es/es/comprar/vivienda/ma...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>172000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40,2998774864376</td>\n",
       "      <td>-3,45226301356237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15330</th>\n",
       "      <td>15331</td>\n",
       "      <td>153901377</td>\n",
       "      <td>False</td>\n",
       "      <td>infocasa consulting</td>\n",
       "      <td>911360461.0</td>\n",
       "      <td>https://www.fotocasa.es/es/comprar/vivienda/ma...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>259470</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40,45416</td>\n",
       "      <td>-3,70286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15331</th>\n",
       "      <td>15332</td>\n",
       "      <td>150394373</td>\n",
       "      <td>False</td>\n",
       "      <td>inmobiliaria pulpon</td>\n",
       "      <td>912788039.0</td>\n",
       "      <td>https://www.fotocasa.es/es/comprar/vivienda/ma...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>165000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40,36652</td>\n",
       "      <td>-3,48951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15332</th>\n",
       "      <td>15333</td>\n",
       "      <td>153901397</td>\n",
       "      <td>False</td>\n",
       "      <td>tecnocasa torrelodones</td>\n",
       "      <td>912780348.0</td>\n",
       "      <td>https://www.fotocasa.es/es/comprar/vivienda/ma...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>495000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40,57444</td>\n",
       "      <td>-3,92124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15333</th>\n",
       "      <td>15334</td>\n",
       "      <td>152607440</td>\n",
       "      <td>False</td>\n",
       "      <td>inmobiliaria pulpon</td>\n",
       "      <td>912788039.0</td>\n",
       "      <td>https://www.fotocasa.es/es/comprar/vivienda/ma...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>195000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40,36967</td>\n",
       "      <td>-3,48105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15334</th>\n",
       "      <td>15335</td>\n",
       "      <td>153901356</td>\n",
       "      <td>False</td>\n",
       "      <td>infocasa consulting</td>\n",
       "      <td>911360461.0</td>\n",
       "      <td>https://www.fotocasa.es/es/comprar/vivienda/ma...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>765000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40,45773</td>\n",
       "      <td>-3,69068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15335 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  id_realEstates  isNew                    realEstate_name  \\\n",
       "0               1       153771986  False            ferrari 57 inmobiliaria   \n",
       "1               2       153867863  False  tecnocasa fuenlabrada ferrocarril   \n",
       "2               3       153430440  False                 look find boadilla   \n",
       "3               4       152776331  False  tecnocasa fuenlabrada ferrocarril   \n",
       "4               5       153180188  False            ferrari 57 inmobiliaria   \n",
       "...           ...             ...    ...                                ...   \n",
       "15330       15331       153901377  False                infocasa consulting   \n",
       "15331       15332       150394373  False                inmobiliaria pulpon   \n",
       "15332       15333       153901397  False             tecnocasa torrelodones   \n",
       "15333       15334       152607440  False                inmobiliaria pulpon   \n",
       "15334       15335       153901356  False                infocasa consulting   \n",
       "\n",
       "       phone_realEstate                                       url_inmueble  \\\n",
       "0           912177526.0  https://www.fotocasa.es/es/comprar/vivienda/ma...   \n",
       "1           916358736.0  https://www.fotocasa.es/es/comprar/vivienda/ma...   \n",
       "2           916350408.0  https://www.fotocasa.es/es/comprar/vivienda/ma...   \n",
       "3           916358736.0  https://www.fotocasa.es/es/comprar/vivienda/ma...   \n",
       "4           912177526.0  https://www.fotocasa.es/es/comprar/vivienda/ma...   \n",
       "...                 ...                                                ...   \n",
       "15330       911360461.0  https://www.fotocasa.es/es/comprar/vivienda/ma...   \n",
       "15331       912788039.0  https://www.fotocasa.es/es/comprar/vivienda/ma...   \n",
       "15332       912780348.0  https://www.fotocasa.es/es/comprar/vivienda/ma...   \n",
       "15333       912788039.0  https://www.fotocasa.es/es/comprar/vivienda/ma...   \n",
       "15334       911360461.0  https://www.fotocasa.es/es/comprar/vivienda/ma...   \n",
       "\n",
       "       rooms  bathrooms  surface   price  ... level4Id level5Id level6Id  \\\n",
       "0        3.0        2.0    103.0  195000  ...        0        0        0   \n",
       "1        3.0        1.0      NaN   89000  ...        0        0        0   \n",
       "2        2.0        2.0     99.0  390000  ...        0        0        0   \n",
       "3        3.0        1.0     86.0   89000  ...        0        0        0   \n",
       "4        2.0        2.0    106.0  172000  ...        0        0        0   \n",
       "...      ...        ...      ...     ...  ...      ...      ...      ...   \n",
       "15330    2.0        1.0     96.0  259470  ...        0        0        0   \n",
       "15331    3.0        1.0    150.0  165000  ...        0        0        0   \n",
       "15332    4.0        2.0    175.0  495000  ...        0        0        0   \n",
       "15333    3.0        2.0    101.0  195000  ...        0        0        0   \n",
       "15334    3.0        2.0    152.0  765000  ...        0        0        0   \n",
       "\n",
       "      level7Id level8Id accuracy          latitude          longitude zipCode  \\\n",
       "0            0        0        0  40,2948276786438  -3,44402412135624     NaN   \n",
       "1            0        0        1          40,28674           -3,79351     NaN   \n",
       "2            0        0        0  40,4115646786438  -3,90662252135624     NaN   \n",
       "3            0        0        0  40,2853785786438  -3,79508142135624     NaN   \n",
       "4            0        0        0  40,2998774864376  -3,45226301356237     NaN   \n",
       "...        ...      ...      ...               ...                ...     ...   \n",
       "15330        0        0        0          40,45416           -3,70286     NaN   \n",
       "15331        0        0        0          40,36652           -3,48951     NaN   \n",
       "15332        0        0        0          40,57444           -3,92124     NaN   \n",
       "15333        0        0        0          40,36967           -3,48105     NaN   \n",
       "15334        0        0        0          40,45773           -3,69068     NaN   \n",
       "\n",
       "      customZone  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "...          ...  \n",
       "15330        NaN  \n",
       "15331        NaN  \n",
       "15332        NaN  \n",
       "15333        NaN  \n",
       "15334        NaN  \n",
       "\n",
       "[15335 rows x 37 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This CSV file contains semicolons instead of comas as separator\n",
    "ds = pd.read_csv('assets/real_estate.csv', sep=';')\n",
    "ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "latin-guest",
   "metadata": {},
   "source": [
    "#### Exercise 01. Which is the most expensive house in the dataset? (★☆☆)\n",
    "\n",
    "Print the address and the price of the selected house. For example:\n",
    "\n",
    "`The house with address General Street Nº5 is the most expensive and its price is 5000000 USD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "developing-optimum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The house with address El Escorial is the most expensive and its price is 8500000 USD.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This CSV file contains semicolons instead of comas as separator\n",
    "ds = pd.read_csv('assets/real_estate.csv', sep=';')\n",
    "ds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Find the most expensive house\n",
    "most_expensive = ds.loc[ds['price'].idxmax()]  # Assuming 'price' is the column with house prices\n",
    "\n",
    "# Display the details of the most expensive house\n",
    "address = most_expensive['address']  # Assuming 'address' is the column for house addresses\n",
    "price = most_expensive['price']\n",
    "\n",
    "print(f\"The house with address {address} is the most expensive and its price is {price} USD.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "lesser-cosmetic",
   "metadata": {},
   "source": [
    "#### Exercise 02. Which is the cheapest house in the dataset? (★☆☆)\n",
    "\n",
    "Print the address and the price of the selected house. For example:\n",
    "\n",
    "`The house with address Concrete Street Nº1 is the cheapest and its price is 12000 USD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lovely-oasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The house with address Parla is the cheapest and its price is 0 USD.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find the cheapest house\n",
    "cheapest_house = ds.loc[ds['price'].idxmin()]  # Assuming 'price' is the column with house prices\n",
    "\n",
    "# Extract details of the cheapest house\n",
    "address = cheapest_house['address']  # Assuming 'address' is the column for house addresses\n",
    "price = cheapest_house['price']\n",
    "\n",
    "# Print the result\n",
    "print(f\"The house with address {address} is the cheapest and its price is {price} USD.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "compliant-fellowship",
   "metadata": {},
   "source": [
    "#### Exercise 03. Which is the biggest and the smallest house in the dataset? (★☆☆)\n",
    "\n",
    "Print both the address and the surface of the selected houses. For example:\n",
    "\n",
    "`The biggest house is located on Yukka Street Nº10 and its surface is 5000 meters`\n",
    "\n",
    "`The smallest house is located on County Road 1 N and its surface is 200 meters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "every-tiffany",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\rober ugalde\\\\Documents\\\\real_estate.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrober ugalde\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mreal_estate.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Find the biggest house\u001b[39;00m\n\u001b[1;32m      8\u001b[0m biggest_house \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mloc[ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurface\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39midxmax()]  \u001b[38;5;66;03m# Assuming 'surface' is the column for house surface areas\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\rober ugalde\\\\Documents\\\\real_estate.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\rober ugalde\\Documents\\real_estate.csv'\n",
    "ds = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Find the biggest house\n",
    "biggest_house = ds.loc[ds['surface'].idxmax()]  # Assuming 'surface' is the column for house surface areas\n",
    "biggest_address = biggest_house['address']  # Assuming 'address' is the column for house addresses\n",
    "biggest_surface = biggest_house['surface']\n",
    "\n",
    "# Find the smallest house\n",
    "smallest_house = ds.loc[ds['surface'].idxmin()]\n",
    "smallest_address = smallest_house['address']\n",
    "smallest_surface = smallest_house['surface']\n",
    "\n",
    "# Print the results\n",
    "print(f\"The biggest house is located on {biggest_address} and its surface is {biggest_surface} meters.\")\n",
    "print(f\"The smallest house is located on {smallest_address} and its surface is {smallest_surface} meters.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "danish-spirit",
   "metadata": {},
   "source": [
    "#### Exercise 04. How many populations (level5 column) the dataset contains? (★☆☆)\n",
    "\n",
    "Print the names of the populations with a comma as a separator. For example:\n",
    "\n",
    "`> print(populations)`\n",
    "\n",
    "`population1, population2, population3, ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\rober ugalde\\Documents\\real_estate.csv'\n",
    "ds = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Get unique populations from the 'level5' column\n",
    "populations = ds['level5'].unique()  # Assuming 'level5' is the column for populations\n",
    "\n",
    "# Convert the array to a comma-separated string\n",
    "populations_list = ', '.join(populations)\n",
    "\n",
    "# Print the names of the populations\n",
    "print(f\"Populations: {populations_list}\")\n",
    "\n",
    "# Print the total number of unique populations\n",
    "print(f\"Number of populations: {len(populations)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "crazy-blame",
   "metadata": {},
   "source": [
    "#### Exercise 05. Does the dataset contain NAs? (★☆☆)\n",
    "\n",
    "Print a boolean value (`True` or `False`) followed by the rows/cols that contains NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\rober ugalde\\Documents\\real_estate.csv'\n",
    "ds = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Check if the dataset contains any NAs\n",
    "contains_nas = ds.isnull().values.any()\n",
    "\n",
    "# Print whether the dataset contains NAs\n",
    "print(f\"Contains NAs: {contains_nas}\")\n",
    "\n",
    "if contains_nas:\n",
    "    # Print rows with NAs\n",
    "    rows_with_nas = ds[ds.isnull().any(axis=1)]\n",
    "    print(\"\\nRows with NAs:\")\n",
    "    print(rows_with_nas)\n",
    "    \n",
    "    # Print columns with NAs\n",
    "    cols_with_nas = ds.columns[ds.isnull().any()].tolist()\n",
    "    print(\"\\nColumns with NAs:\")\n",
    "    print(cols_with_nas)\n",
    "else:\n",
    "    print(\"The dataset does not contain any NAs.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "italic-hydrogen",
   "metadata": {},
   "source": [
    "#### Exercise 06. Delete the NAs of the dataset, if applicable (★★☆)\n",
    "\n",
    "Print a comparison between the dimensions of the original DataFrame versus the DataFrame after the deletions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\rober ugalde\\Documents\\real_estate.csv'\n",
    "ds = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Store original dimensions\n",
    "original_shape = ds.shape\n",
    "\n",
    "# Remove rows with NAs\n",
    "ds_cleaned = ds.dropna()\n",
    "\n",
    "# Store cleaned dimensions\n",
    "cleaned_shape = ds_cleaned.shape\n",
    "\n",
    "# Print comparison of dimensions\n",
    "print(f\"Original DataFrame dimensions: {original_shape}\")\n",
    "print(f\"DataFrame dimensions after removing NAs: {cleaned_shape}\")\n",
    "\n",
    "# Check how many rows were removed\n",
    "rows_removed = original_shape[0] - cleaned_shape[0]\n",
    "print(f\"Number of rows removed: {rows_removed}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "middle-china",
   "metadata": {},
   "source": [
    "#### Exercise 07. Which is the mean of prices in the population (level5 column) of \"Arroyomolinos (Madrid)\"? (★★☆)\n",
    "\n",
    "Print the obtained value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\rober ugalde\\Documents\\real_estate.csv'\n",
    "ds = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Filter the dataset for the population \"Arroyomolinos (Madrid)\"\n",
    "arroyomolinos_data = ds[ds['level5'] == 'Arroyomolinos (Madrid)']  # Assuming 'level5' is the population column\n",
    "\n",
    "# Calculate the mean price\n",
    "mean_price = arroyomolinos_data['price'].mean()  # Assuming 'price' is the price column\n",
    "\n",
    "# Print the mean price\n",
    "print(f\"The mean price of houses in 'Arroyomolinos (Madrid)' is {mean_price:.2f} USD.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "concerned-radical",
   "metadata": {},
   "source": [
    "#### Exercise 08. Plot the histogram of prices for the population (level5 column) of \"Arroyomolinos (Madrid)\" and explain what you observe (★★☆)\n",
    "\n",
    "Print the histogram of the prices and write in the Markdown cell a brief analysis about the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\rober ugalde\\Documents\\real_estate.csv'\n",
    "ds = pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Filter the dataset for the population \"Arroyomolinos (Madrid)\"\n",
    "arroyomolinos_data = ds[ds['level5'] == 'Arroyomolinos (Madrid)']  # Assuming 'level5' is the population column\n",
    "\n",
    "# Extract prices for the filtered population\n",
    "prices = arroyomolinos_data['price']  # Assuming 'price' is the price column\n",
    "\n",
    "# Plot the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(prices, bins=10, color='skyblue', alpha=0.8, edgecolor='black')\n",
    "plt.title(\"Histogram of Prices in 'Arroyomolinos (Madrid)'\", fontsize=16)\n",
    "plt.xlabel(\"Price (USD)\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "Observations and Analysis:\n",
    "Price Distribution:\n",
    "\n",
    "The histogram will show the spread of property prices \n",
    "in \"Arroyomolinos (Madrid).\" For example:\n",
    "If the bars are concentrated around a specific range,\n",
    " it suggests most properties are priced similarly.\n",
    "A wider spread indicates diverse pricing.\n",
    "Peaks:\n",
    "\n",
    "Peaks (tall bars) in the histogram represent price ranges \n",
    "with a high number of properties.\n",
    "A peak at a lower price range might suggest affordability in that area.\n",
    "\n",
    "Outliers:\n",
    "\n",
    "If there are bars far away from the rest of the distribution,\n",
    " it may indicate outliers, such as luxury home\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "impressed-combination",
   "metadata": {},
   "source": [
    "**TODO: Markdown**. To write here, double-click on this cell, remove this content and place the text you want to write. Then, execute the cell."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "actual-edinburgh",
   "metadata": {},
   "source": [
    "#### Exercise 09. Are the average prices of \"Valdemorillo\" and \"Galapagar\" the same? (★★☆)\n",
    "\n",
    "Print both average prices and then write a conclusion about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "lonely-article",
   "metadata": {},
   "source": [
    "#### Exercise 10. Are the average prices per square meter (price/m2) of \"Valdemorillo\" and \"Galapagar\" the same? (★★☆)\n",
    "\n",
    "Print both average prices and then write a conclusion about it.\n",
    "\n",
    "Hint: Create a new column called `pps` (price per square meter) and then analyze the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "pleasant-invite",
   "metadata": {},
   "source": [
    "#### Exercise 11. Analyze the relation between the surface and the price of the houses (★★☆)\n",
    "\n",
    "Hint: You can make a `scatter plot`, then write a conclusion about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ahead-liquid",
   "metadata": {},
   "source": [
    "**TODO: Markdown**. To write here, double-click on this cell, remove this content and place the text you want to write. Then, execute the cell."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "coordinate-sunrise",
   "metadata": {},
   "source": [
    "#### Exercise 12. How many real estate agencies does the dataset contain? (★★☆)\n",
    "\n",
    "Print the obtained value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "binding-ebony",
   "metadata": {},
   "source": [
    "#### Exercise 13. Which is the population (level5 column) that contains the most houses? (★★☆)\n",
    "\n",
    "Print both the population and the number of houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "entire-classification",
   "metadata": {},
   "source": [
    "#### Exercise 14. Now let's work with the \"south belt\" of Madrid. Make a subset of the original DataFrame that contains the following populations (level5 column): \"Fuenlabrada\", \"Leganés\", \"Getafe\", \"Alcorcón\" (★★☆)\n",
    "\n",
    "Hint: Filter the original DataFrame using the column `level5` and the function `isin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "severe-fisher",
   "metadata": {},
   "source": [
    "#### Exercise 15. Make a bar plot of the median of the prices and explain what you observe (you must use the subset obtained in Exercise 14) (★★★)\n",
    "\n",
    "Print the bar of the median of the prices and write in the Markdown cell a brief analysis about the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sublime-newspaper",
   "metadata": {},
   "source": [
    "**TODO: Markdown**. To write here, double-click on this cell, remove this content and place the text you want to write. Then, execute the cell."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "speaking-diamond",
   "metadata": {},
   "source": [
    "#### Exercise 16. Calculate the sample mean and variance of the variables: price, rooms, surface area and bathrooms (you must use the subset obtained in Exercise 14) (★★★)\n",
    "\n",
    "Print both values for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "revolutionary-matrix",
   "metadata": {},
   "source": [
    "#### Exercise 17. What is the most expensive house in each population? You must use the subset obtained in Exercise 14 (★★☆)\n",
    "\n",
    "Print both the address and the price of the selected house of each population. You can print a DataFrame or a single line for each population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "activated-knight",
   "metadata": {},
   "source": [
    "#### Exercise 18. Normalize the variable of prices for each population and plot the 4 histograms in the same plot (you must use the subset obtained in Exercise 14) (★★★)\n",
    "\n",
    "For the normalization method, you can use the one you consider; there is not a single correct answer to this question. Print the plot and write in the Markdown cell a brief analysis about the plot.\n",
    "\n",
    "Hint: You can help yourself by reviewing the *multihist* demo of Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "precise-heavy",
   "metadata": {},
   "source": [
    "**TODO: Markdown**. To write here, double-click on this cell, remove this content and place the text you want to write. Then, execute the cell."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "patent-jonathan",
   "metadata": {},
   "source": [
    "#### Exercise 19. What can you say about the price per square meter (price/m2) between the towns of \"Getafe\" and \"Alcorcón\"? You must use the subset obtained in Exercise 14 (★★☆)\n",
    "\n",
    "Hint: Create a new column called `pps` (price per square meter) and then analyze the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "enhanced-moscow",
   "metadata": {},
   "source": [
    "#### Exercise 20. Make the same plot for 4 different populations (level5 column) and rearrange them on the same graph. You must use the subset obtained in Exercise 14 (★★☆)\n",
    " \n",
    "Hint: Make a scatter plot of each population using subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "blocked-effects",
   "metadata": {},
   "source": [
    "#### Exercise 21. Make a plot of the coordinates (latitude and longitude columns) of the south belt of Madrid by color of each population (you must use the subset obtained in Exercise 14) (★★★★)\n",
    "\n",
    "Execute the following cell, and then start coding in the next one. You must implement a simple code that transforms the coordinates columns in a Python dictionary (add more information if needed) and then add it to the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, basemaps\n",
    "\n",
    "# Map centered on (60 degrees latitude and -2.2 degrees longitude)\n",
    "# Latitude, longitude\n",
    "map = Map(center = (60, -2.2), zoom = 2, min_zoom = 1, max_zoom = 20, \n",
    "    basemap=basemaps.Stamen.Terrain)\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HERE: plot the coordinates of the estates\n",
    "\n",
    "## PUT HERE YOUR CODE:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
